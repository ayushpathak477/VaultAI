{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjJNoiMO3LEe",
        "outputId": "b2d8eabd-78d7-4138-9ea7-d33aa1723874"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting brute-force simulation...\n",
            "\n",
            "Brute-force cracked password: abc\n",
            "Attempts: 3971, Time: 0.0000 seconds\n",
            "\n",
            "Simulated Hashcat cracking time: 0.0000 seconds (Entropy: 14.10 bits)\n",
            "\n",
            "XAI Explanation:\n",
            "\n",
            "Password: abc\n",
            "Brute-force simulation: 3971 attempts in 0.0000 seconds.\n",
            "Estimated entropy: 14.10 bits\n",
            "Total possibilities: 1.76e+04\n",
            "Simulated Hashcat cracking time: 0.0000 seconds.\n",
            "\n",
            "Analysis: The password can be cracked almost instantly with advanced tools. It is highly vulnerable.\n",
            "Your password does not closely resemble common patterns.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "import time\n",
        "import math\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# Brute-force password cracking simulation\n",
        "def brute_force(target_password, max_length=None):\n",
        "    \"\"\"\n",
        "    Simulate brute-force cracking by iterating through combinations.\n",
        "    For demonstration, the search stops at max_length (defaults to len(target_password)).\n",
        "    Returns the cracked password, number of attempts, and elapsed time.\n",
        "    \"\"\"\n",
        "    chars = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
        "    if max_length is None:\n",
        "        max_length = len(target_password)\n",
        "    length = 1\n",
        "    attempts = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    while length <= max_length:\n",
        "        for attempt in itertools.product(chars, repeat=length):\n",
        "            guess = ''.join(attempt)\n",
        "            attempts += 1\n",
        "            # For demonstration, we print only every 10000th attempt to avoid flooding the output\n",
        "            if attempts % 10000 == 0:\n",
        "                print(f\"Brute-force attempt {attempts}: {guess}\")\n",
        "            if guess == target_password:\n",
        "                elapsed = time.time() - start_time\n",
        "                return guess, attempts, elapsed\n",
        "        length += 1\n",
        "    return None, attempts, time.time() - start_time\n",
        "\n",
        "# Simulated Hashcat analysis based on entropy calculation\n",
        "def hashcat_simulation(target_password):\n",
        "    \"\"\"\n",
        "    Estimates the cracking time using an entropy-based model.\n",
        "    Calculates the number of possible combinations and simulates a cracking time\n",
        "    given a hypothetical guess rate.\n",
        "    \"\"\"\n",
        "    # Define the character pool based on the password's composition\n",
        "    pool = 0\n",
        "    if any(c.islower() for c in target_password):\n",
        "        pool += 26\n",
        "    if any(c.isupper() for c in target_password):\n",
        "        pool += 26\n",
        "    if any(c.isdigit() for c in target_password):\n",
        "        pool += 10\n",
        "    if any(not c.isalnum() for c in target_password):\n",
        "        pool += 32  # common symbols estimate\n",
        "\n",
        "    if pool == 0:\n",
        "        pool = 1  # avoid division by zero\n",
        "\n",
        "    # Estimate entropy (bits)\n",
        "    entropy = len(target_password) * math.log2(pool)\n",
        "\n",
        "    # Calculate total possibilities and simulated time (using a hypothetical guess rate)\n",
        "    possibilities = 2 ** entropy\n",
        "    hashcat_rate = 1e11  # e.g., 100 billion guesses per second\n",
        "    time_estimate = possibilities / hashcat_rate\n",
        "    return entropy, possibilities, time_estimate\n",
        "\n",
        "# XAI explanation based on the results from brute-force and hashcat simulation\n",
        "def generate_xai_explanation(target_password, brute_info, hashcat_info):\n",
        "    \"\"\"\n",
        "    Combines the brute-force results and simulated hashcat analysis to explain password strength.\n",
        "    Also uses a similarity metric against a common password pattern.\n",
        "    \"\"\"\n",
        "    guessed, attempts, brute_time = brute_info\n",
        "    entropy, possibilities, hashcat_time = hashcat_info\n",
        "\n",
        "    explanation = f\"Password: {target_password}\\n\"\n",
        "    explanation += f\"Brute-force simulation: {attempts} attempts in {brute_time:.4f} seconds.\\n\"\n",
        "    explanation += f\"Estimated entropy: {entropy:.2f} bits\\n\"\n",
        "    explanation += f\"Total possibilities: {possibilities:.2e}\\n\"\n",
        "    explanation += f\"Simulated Hashcat cracking time: {hashcat_time:.4f} seconds.\\n\\n\"\n",
        "\n",
        "    # Explain vulnerability based on simulated cracking times\n",
        "    if hashcat_time < 1:\n",
        "        explanation += \"Analysis: The password can be cracked almost instantly with advanced tools. It is highly vulnerable.\\n\"\n",
        "    elif hashcat_time < 60:\n",
        "        explanation += \"Analysis: The password is weak and could be compromised within a minute by dedicated attackers.\\n\"\n",
        "    else:\n",
        "        explanation += \"Analysis: The password has higher complexity, making it more resistant to brute-force attacks.\\n\"\n",
        "\n",
        "    # Similarity check with a common password (e.g., 'password')\n",
        "    common_password = \"password\"\n",
        "    similarity = SequenceMatcher(None, target_password, common_password).ratio()\n",
        "    if similarity > 0.5:\n",
        "        explanation += \"Warning: Your password bears similarity to common password patterns, which increases vulnerability.\\n\"\n",
        "    else:\n",
        "        explanation += \"Your password does not closely resemble common patterns.\\n\"\n",
        "\n",
        "    return explanation\n",
        "\n",
        "# Main function: Get user input and run the analysis\n",
        "def main():\n",
        "    target = input(\"Enter the password for analysis: \").strip()\n",
        "\n",
        "    print(\"\\nStarting brute-force simulation...\")\n",
        "    brute_info = brute_force(target, max_length=len(target))\n",
        "    if brute_info[0]:\n",
        "        print(f\"\\nBrute-force cracked password: {brute_info[0]}\")\n",
        "        print(f\"Attempts: {brute_info[1]}, Time: {brute_info[2]:.4f} seconds\")\n",
        "    else:\n",
        "        print(\"\\nBrute-force simulation did not crack the password within the max length limit.\")\n",
        "\n",
        "    hashcat_info = hashcat_simulation(target)\n",
        "    entropy, possibilities, hashcat_time = hashcat_info\n",
        "    print(f\"\\nSimulated Hashcat cracking time: {hashcat_time:.4f} seconds (Entropy: {entropy:.2f} bits)\")\n",
        "\n",
        "    explanation = generate_xai_explanation(target, brute_info, hashcat_info)\n",
        "    print(\"\\nXAI Explanation:\\n\")\n",
        "    print(explanation)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAp0q-upprhF",
        "outputId": "4a1957d5-5970-460a-8473-6516ed874c96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rockyou.txt already exists. Skipping download and extraction.\n",
            "\n",
            "Loading rockyou.txt into DataFrame...\n",
            "Loaded 14344376 passwords.\n",
            "\n",
            "Filtering for gold standard passwords... (This may take a few minutes)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 14344376/14344376 [00:16<00:00, 885991.57it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Found 4617 gold standard passwords that meet all criteria.\n",
            "Gold standard dataset saved to 'gold_standard_passwords.csv'\n",
            "\n",
            "Sample of these passwords:\n",
            "                  password\n",
            "440535        ABCabc123!@#\n",
            "503191       iydgTv8ogfup;\n",
            "702300        abcABC123!@#\n",
            "703230      Tinkerbell@174\n",
            "710124       Eussdqen1968.\n",
            "737713        123qwe!@#QWE\n",
            "738409        123!@#qweQWE\n",
            "919664   iyd86Ig-hkvudc]h;\n",
            "1050594       Junior@last2\n",
            "1051169   JaY14$P.rBoricua\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import tarfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import math\n",
        "from collections import Counter\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# --- 1. Define the ULTIMATE Criteria for a Strong Password ---\n",
        "def is_truly_strong(password):\n",
        "    \"\"\"Checks if a password meets all our criteria for being strong.\"\"\"\n",
        "    if not isinstance(password, str):\n",
        "        return False\n",
        "    \n",
        "    # Rule 1: Length must be between 10 and 20 characters\n",
        "    if not (10 <= len(password) <= 20):\n",
        "        return False\n",
        "    \n",
        "    # Rule 2: Must contain at least one of each character type\n",
        "    if not (re.search(r'[a-z]', password) and\n",
        "            re.search(r'[A-Z]', password) and\n",
        "            re.search(r'[0-9]', password) and\n",
        "            re.search(r'[^a-zA-Z0-9]', password)):\n",
        "        return False\n",
        "        \n",
        "    # Rule 3: Shannon Entropy must be above 3.5\n",
        "    char_counts = Counter(password)\n",
        "    entropy = sum([- (count / len(password)) * math.log2(count / len(password)) for count in char_counts.values()])\n",
        "    if entropy < 3.5:\n",
        "        return False\n",
        "        \n",
        "    return True\n",
        "\n",
        "# --- 2. Download and Extract the RockYou Dataset ---\n",
        "archive_name = \"rockyou.txt.tar.gz\"\n",
        "text_file_name = \"rockyou.txt\"\n",
        "output_filename = 'gold_standard_passwords.csv'\n",
        "\n",
        "if not os.path.exists(text_file_name):\n",
        "    print(f\"{text_file_name} not found. Starting download...\")\n",
        "    url = \"https://github.com/danielmiessler/SecLists/raw/master/Passwords/Leaked-Databases/rockyou.txt.tar.gz\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        with open(archive_name, \"wb\") as file:\n",
        "            file.write(response.content)\n",
        "        print(f\"Downloaded {archive_name} successfully.\")\n",
        "        \n",
        "        print(\"Extracting archive...\")\n",
        "        with tarfile.open(archive_name, \"r:gz\") as tar:\n",
        "            tar.extractall()\n",
        "        print(\"Extraction complete.\")\n",
        "    else:\n",
        "        print(f\"Failed to download the dataset. Status code: {response.status_code}\")\n",
        "else:\n",
        "    print(f\"{text_file_name} already exists. Skipping download and extraction.\")\n",
        "\n",
        "# --- 3. Load and Filter the Dataset ---\n",
        "print(\"\\nLoading rockyou.txt into DataFrame...\")\n",
        "try:\n",
        "    # ** THE FIX IS HERE: Added encoding='latin-1' **\n",
        "    df = pd.read_csv(text_file_name, sep='\\\\n', header=None, names=['password'], engine='python', on_bad_lines='skip', encoding='latin-1')\n",
        "    \n",
        "    df.dropna(inplace=True)\n",
        "    print(f\"Loaded {len(df)} passwords.\")\n",
        "\n",
        "    print(\"\\nFiltering for gold standard passwords... (This may take a few minutes)\")\n",
        "    tqdm.pandas()\n",
        "    strong_mask = df['password'].progress_apply(is_truly_strong)\n",
        "    strong_df = df[strong_mask]\n",
        "\n",
        "    print(f\"\\nFound {len(strong_df)} gold standard passwords that meet all criteria.\")\n",
        "\n",
        "    if not strong_df.empty:\n",
        "        strong_df.to_csv(output_filename, index=False, header=['password'])\n",
        "        print(f\"Gold standard dataset saved to '{output_filename}'\")\n",
        "        print(\"\\nSample of these passwords:\")\n",
        "        print(strong_df.head(10))\n",
        "    else:\n",
        "        print(\"No passwords met all the strong criteria.\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during processing: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxZ8RMv-vsO1",
        "outputId": "96156bba-3344-4d2f-ce11-9413e78565e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading the high-entropy password dataset...\n",
            "Loaded 3378549 high-entropy passwords for training.\n",
            "Vocabulary size for strong passwords: 206\n",
            "Creating input/output sequences for the model...\n",
            "Total training patterns: 5384202\n",
            "\n",
            "Building the advanced LSTM model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,052,672</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">206</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">105,678</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m1,052,672\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m2,099,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m2,099,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m206\u001b[0m)            │       \u001b[38;5;34m105,678\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,619,406</span> (21.44 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,619,406\u001b[0m (21.44 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,619,406</span> (21.44 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,619,406\u001b[0m (21.44 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting model training... (This will take some time)\n",
            "Epoch 1/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1967s\u001b[0m 3s/step - accuracy: 0.0923 - loss: 3.4801\n",
            "Epoch 2/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 350ms/step - accuracy: 0.1511 - loss: 2.9648\n",
            "Epoch 3/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 352ms/step - accuracy: 0.1609 - loss: 2.9157\n",
            "Epoch 4/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 351ms/step - accuracy: 0.1695 - loss: 2.8857\n",
            "Epoch 5/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 351ms/step - accuracy: 0.1728 - loss: 2.8627\n",
            "Epoch 6/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 350ms/step - accuracy: 0.1778 - loss: 2.8517\n",
            "Epoch 7/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 358ms/step - accuracy: 0.1852 - loss: 2.8149\n",
            "Epoch 8/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 357ms/step - accuracy: 0.1915 - loss: 2.7923\n",
            "Epoch 9/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 362ms/step - accuracy: 0.2000 - loss: 2.7672\n",
            "Epoch 10/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 355ms/step - accuracy: 0.2067 - loss: 2.7390\n",
            "Epoch 11/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 361ms/step - accuracy: 0.2153 - loss: 2.7002\n",
            "Epoch 12/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 356ms/step - accuracy: 0.2229 - loss: 2.6780\n",
            "Epoch 13/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 356ms/step - accuracy: 0.2330 - loss: 2.6432\n",
            "Epoch 14/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 357ms/step - accuracy: 0.2424 - loss: 2.6083\n",
            "Epoch 15/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 359ms/step - accuracy: 0.2516 - loss: 2.5663\n",
            "Epoch 16/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 356ms/step - accuracy: 0.2578 - loss: 2.5407\n",
            "Epoch 17/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1181s\u001b[0m 2s/step - accuracy: 0.2699 - loss: 2.4986\n",
            "Epoch 18/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 406ms/step - accuracy: 0.2745 - loss: 2.4732\n",
            "Epoch 19/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 374ms/step - accuracy: 0.2817 - loss: 2.4467\n",
            "Epoch 20/20\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 369ms/step - accuracy: 0.2926 - loss: 2.4021\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training complete. New model saved as 'strong_password_generator.h5'\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import json\n",
        "\n",
        "# --- 1. Load the GOLD STANDARD High-Entropy Dataset ---\n",
        "print(\"Loading the gold standard password dataset...\")\n",
        "try:\n",
        "    # <-- THE FIX IS HERE: Updated the filename\n",
        "    df_strong = pd.read_csv('gold_standard_passwords.csv')\n",
        "    \n",
        "    print(f\"--> Training on exactly {len(df_strong)} high-entropy passwords.\")\n",
        "    high_entropy_passwords = df_strong['password'].dropna().astype(str).values\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'gold_standard_passwords.csv' not found. Please run the previous cell first.\")\n",
        "    raise\n",
        "\n",
        "# --- 2. Prepare Data for the RNN Model ---\n",
        "chars = sorted(list(set(''.join(high_entropy_passwords))))\n",
        "char_to_int = {ch: idx for idx, ch in enumerate(chars)}\n",
        "int_to_char = {idx: ch for idx, ch in enumerate(chars)}\n",
        "vocab_size = len(chars)\n",
        "print(f\"Vocabulary size for strong passwords: {vocab_size}\")\n",
        "\n",
        "seq_length = 10 \n",
        "X = []\n",
        "y = []\n",
        "print(\"Creating input/output sequences for the model...\")\n",
        "for password in high_entropy_passwords:\n",
        "    if len(password) > seq_length:\n",
        "        for i in range(len(password) - seq_length):\n",
        "            seq_in = password[i:i + seq_length]\n",
        "            seq_out = password[i + seq_length]\n",
        "            X.append([char_to_int.get(char, 0) for char in seq_in])\n",
        "            y.append(char_to_int.get(seq_out, 0))\n",
        "\n",
        "num_patterns = len(X)\n",
        "print(f\"Total training patterns: {num_patterns}\")\n",
        "X_reshaped = np.reshape(X, (num_patterns, seq_length, 1))\n",
        "X_reshaped = X_reshaped / float(vocab_size)\n",
        "y_categorical = to_categorical(y, num_classes=vocab_size)\n",
        "\n",
        "# --- 3. Build the SIMPLER LSTM Model ---\n",
        "print(\"\\nBuilding a simpler, more robust LSTM model...\")\n",
        "model = Sequential([\n",
        "    Input(shape=(X_reshaped.shape[1], X_reshaped.shape[2])),\n",
        "    LSTM(256, return_sequences=True),\n",
        "    Dropout(0.3),\n",
        "    LSTM(256),\n",
        "    Dropout(0.3),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# --- 4. Train the Model ---\n",
        "print(\"\\nStarting model training... (This will take some time)\")\n",
        "# For a full run, you can increase the subset_size or remove the slicing\n",
        "subset_size = 100000 \n",
        "model.fit(X_reshaped[:subset_size], y_categorical[:subset_size], epochs=20, batch_size=128)\n",
        "\n",
        "# --- 5. Save the New Model AND the Vocabulary ---\n",
        "new_model_filename = 'strong_password_generator.h5'\n",
        "vocab_filename = 'char_to_int.json'\n",
        "\n",
        "model.save(new_model_filename)\n",
        "with open(vocab_filename, 'w') as f:\n",
        "    json.dump(char_to_int, f)\n",
        "\n",
        "print(f\"\\nTraining complete. New model saved as '{new_model_filename}'\")\n",
        "print(f\"Vocabulary saved as '{vocab_filename}'\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPdAIc10uCRyBTNTwkx/keP",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.10.0)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
